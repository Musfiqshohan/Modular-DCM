{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from modularTraining.constantFunctions import get_dataloaders, Parameters\n",
    "from utils.constant import ATTRIBUTES\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from datamodules.celebadatamodule import CelebADataModule\n",
    "from lightningmodules.classification import Classification\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "################################ Classification\n",
    "from dataclasses import dataclass\n",
    "import os, os.path as osp\n",
    "from typing import Any, ClassVar, Dict, List, Optional\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "from modularTraining.constantFunctions import get_idata\n",
    "\n",
    "\n",
    "\n",
    "def get_prediction(classifier, trainer, images):\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            # transforms.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    data_list = []\n",
    "    for img in images:\n",
    "        lbl = torch.zeros(40, 1)\n",
    "        data_list.append([transform(img), lbl])\n",
    "\n",
    "    predict_loader = DataLoader(dataset=data_list, batch_size=1, shuffle=False)\n",
    "    prediction = trainer.predict(classifier, predict_loader)  # without fine-tuning\n",
    "    all = []\n",
    "    for idx, data_input in enumerate(prediction):\n",
    "        pred = data_input[2][0]\n",
    "        all.append(pred)\n",
    "    return all\n",
    "\n",
    "\n",
    "def get_label_distribution(data_loader):\n",
    "    found = {}\n",
    "    error=[]\n",
    "    flag=0\n",
    "\n",
    "    for lb in attributes:\n",
    "        found[lb] = 0\n",
    "\n",
    "    for i, (img, lbl) in tqdm(enumerate(data_loader)):\n",
    "        predictions = get_prediction(classifier, trainer, img)\n",
    "        for iter,pred in enumerate(predictions):\n",
    "\n",
    "            for lb in pred:\n",
    "                found[lb] += 1\n",
    "\n",
    "            if 'Young' in pred:\n",
    "                print('Found Young')\n",
    "                print(img.shape)\n",
    "                plt.imshow(img[iter].permute(1,2,0))\n",
    "                plt.show()\n",
    "                print(f'Shown {pred}')\n",
    "                error.append(img[iter])\n",
    "\n",
    "\n",
    "        # if i>50:\n",
    "                flag+=1\n",
    "                # break\n",
    "\n",
    "\n",
    "        if flag>=10:\n",
    "            break\n",
    "\n",
    "\n",
    "        # break\n",
    "\n",
    "    print('Attribute found')\n",
    "    # print(found)\n",
    "    # for lb in found:\n",
    "    #     found[lb] = found[lb] / (len(data_loader) * 64) * 100\n",
    "    found = dict(sorted(found.items(), key=lambda item: item[1]))\n",
    "    print(found)\n",
    "\n",
    "    return found, error\n",
    "\n",
    "\n",
    "# def get_idata(name):\n",
    "#     save_folder = f'/local/scratch/a/rahman89/PycharmProjects/modularCelebA/images256/{name}'\n",
    "#\n",
    "#     file = f'{save_folder}/images_10k_I_doMale.pkl'\n",
    "#     with open(file, 'rb') as f:\n",
    "#         intv_images = pickle.load(f)\n",
    "#\n",
    "#     file = f'{save_folder}/labels_10k_I_doMale.pkl'\n",
    "#     with open(file, 'rb') as f:\n",
    "#         intv_labels = pickle.load(f)\n",
    "#\n",
    "#     return intv_labels, intv_images\n",
    "\n",
    "\n",
    "def get_train_test_loaders(dom_name,split_t=0.95, split_v=0.9):\n",
    "    folder = f'/local/scratch/a/rahman89/PycharmProjects/modularCelebA/images256'\n",
    "    file = f'{folder}/8_attribute_10k_celeba_{dom_name}.pkl'\n",
    "    with open(file, 'rb') as f:\n",
    "        domain_dataset = pickle.load(f)\n",
    "\n",
    "    folder = f'/local/scratch/a/rahman89/PycharmProjects/modularCelebA/images256'\n",
    "    file = f'{folder}/images_10k_celeba_{dom_name}.pkl'\n",
    "    with open(file, 'rb') as f:\n",
    "        images = pickle.load(f)\n",
    "\n",
    "    domain_dataset['I'] = images['I']\n",
    "    dom_age = domain_dataset['Young'].reshape(-1, 1).type(torch.FloatTensor)\n",
    "    dom_images = domain_dataset['I']\n",
    "\n",
    "    trainloader, validloader, testloader = get_dataloaders(dom_age, dom_images,split_t=0.95, split_v=0.9)\n",
    "\n",
    "    return domain_dataset, trainloader, validloader, testloader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    # loading the classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attributes = list(ATTRIBUTES.values())\n",
    "config = Parameters()\n",
    "# dataset_module = CelebADataModule(config.data_param)\n",
    "# dataset_module.setup()\n",
    "# train_dataloader = dataset_module.train_dataloader()\n",
    "# val_dataloader = dataset_module.val_dataloader()\n",
    "# dataset_module.setup(stage=\"test\")\n",
    "# test_dataloader = dataset_module.test_dataloader()\n",
    "checkpoint = torch.load(config.inference_param.ckpt_path)\n",
    "classifier = Classification(config.inference_param)\n",
    "classifier.load_state_dict(checkpoint[\"state_dict\"])\n",
    "print('Classifier loaded')\n",
    "trainer = Trainer(devices=config.hparams.gpu, limit_train_batches=0, limit_val_batches=0)\n",
    "print('loaded')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# loading interventional data\n",
    "l1, i1 = get_idata('fake5000')  # getting  1st 5000k data samples\n",
    "l2, i2 = get_idata('fake10000')  # getting 2nd 5000k data samples\n",
    "intv_labels = {}\n",
    "intv_labels['Male'] = np.concatenate([l1['Male'], l2['Male']])\n",
    "intv_labels['Young'] = np.concatenate([l1['Young'], l2['Young']])\n",
    "intv_images = np.concatenate([i1['I'], i2['I']])\n",
    "intv_age = np.array(intv_labels['Young'], dtype='float32').reshape(-1, 1)\n",
    "# trainloaderI, _, _ = get_dataloaders(intv_age, intv_images, split_t=0.95, split_v=0.99)\n",
    "\n",
    "\n",
    "intv_dataset = copy.deepcopy(intv_labels)\n",
    "for key in intv_dataset:\n",
    "    intv_dataset[key] = torch.tensor(intv_dataset[key])\n",
    "intv_dataset['I'] = intv_images\n",
    "male = 0\n",
    "young = 0\n",
    "retfo = (intv_dataset['Male'] == male) & (intv_dataset['Young'] == young)\n",
    "female_old = intv_dataset['Young'][retfo].reshape(-1, 1).type(torch.FloatTensor)\n",
    "female_image = intv_dataset['I'][retfo]\n",
    "m0y0_trainloaderI, _, _ = get_dataloaders(female_old, female_image,split_t=0.95, split_v=0.9)\n",
    "#\n",
    "\n",
    "print('label distribution in female old interventional data')\n",
    "distI= get_label_distribution(m0y0_trainloaderI)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "intv_labels={}\n",
    "\n",
    "male_list=[]\n",
    "young_list=[]\n",
    "img_list=[]\n",
    "for m,y in zip([0], [0]):\n",
    "\tll, ii = get_idata(f'fakeIdom{m}y{y}/images_Idom{m}y{y}.pkl', f'fakeIdom{m}y{y}/labels_Idom{m}y{y}.pkl')  #getting  m0y0 data samples\n",
    "\tmale_list.append(ll['Male'])\n",
    "\tyoung_list.append(ll['Young'])\n",
    "\timg_list.append(ii['I'])\n",
    "\n",
    "intv_labels['Male'] = np.concatenate(male_list)\n",
    "intv_labels['Young'] = np.concatenate(young_list)\n",
    "intv_images =  np.concatenate(img_list)\n",
    "\n",
    "h= intv_images.shape[0]\n",
    "rnices= torch.randint(0, h, (h,))\n",
    "intv_labels['Male']= intv_labels['Male'][rnices]\n",
    "intv_labels['Young']= intv_labels['Young'][rnices]\n",
    "intv_images= intv_images[rnices]\n",
    "\n",
    "#\n",
    "intv_age = np.array(intv_labels['Young'], dtype='float32').reshape(-1,1)\n",
    "trainloaderI, validloaderI, testloaderI = get_dataloaders(intv_age, intv_images, split_t=0.95, split_v=0.9)\n",
    "\n",
    "distI,error= get_label_distribution(trainloaderI)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(error)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "errors =[img.unsqueeze(0) for img in error]\n",
    "errors= torch.cat(errors).to('cuda')\n",
    "errors.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = get_prediction(classifier, trainer, errors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for pred in predictions:\n",
    "    print(pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Classifiers.mobileNet.model import MobileNet\n",
    "num_labels=1\n",
    "save_path =\"/local/scratch/a/rahman89/PycharmProjects/modularCelebA/Classifiers/new_weights\"\n",
    "cur_domain='dom1'\n",
    "cur_checkpoint_path = f'{save_path}/{cur_domain}_model_checkpoint.pth'\n",
    "checkpoint_path = cur_checkpoint_path\n",
    "classifier2 = MobileNet(num_labels).to('cuda')\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "classifier2.load_state_dict(checkpoint['model_state_dict'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for img in errors:\n",
    "    ret= classifier2(img.unsqueeze(0))\n",
    "    print(ret)\n",
    "    plt.imshow(img.cpu().permute(1,2,0))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
